<div align="center">
    <img src="./imgs/logo.png">
    <h1>
        Reading Papers
    </h1>
</div>
个人近期论文阅读笔记，备忘



## 1. Transformers

- Transformer不适合NER任务及其解决方案，[pdf](./papers/Transformer/TENER：Adapting_Transformer_Encoder_for_Named_Entity_Recognition.pdf)，[arXiv](https://arxiv.org/abs/1911.04474)，[知乎](https://zhuanlan.zhihu.com/p/137315695)
- 



## 2. 模型剪枝

- LayerDrop，对每一层进行随机mask，提升模型每一层的鲁棒性，最终可以根据mask概率直接修剪模型，[pdf](./papers/Pruning/Reducing_Transformer_Depth_on_Demand_with_Structured_Dropout.pdf)，[arXiv](https://arxiv.org/pdf/1909.11556.pdf)，[知乎](https://zhuanlan.zhihu.com/p/93207254)



## 3. Dialogue Management

- 对话管理综述(2021)，[pdf](./papers/Dialogue/DialogueManagement/A_Survey_on_Dialog_Management：Recent_Advances_and_Challenges.pdf)



## 4. 多模态

- data2vec，一个适用于视觉、语音、文本的自监督学习框架，[pdf](https://scontent-nrt1-1.xx.fbcdn.net/v/t39.8562-6/271974914_483120576492438_4239522333319653600_n.pdf?_nc_cat=107&ccb=1-5&_nc_sid=ae5e01&_nc_ohc=4-cMR5tUq4QAX8dVp4v&_nc_ht=scontent-nrt1-1.xx&oh=00_AT8Zy56yb0ihUA9DMJnJpw4qb3xjC1Q4UbGwP3k1Lq_Baw&oe=61F3F7D1)，[夕小瑶](https://mp.weixin.qq.com/s/pJqKtqM8WQBm8FbgaxGmpQ)

## 5. 其他

- LSTM+CRF学习率不一致，[苏神博客：你的CRF层学习率可能不够大](https://spaces.ac.cn/archives/7196)
- 
